deepspeed --num_gpus 8 --num_nodes 1 llama-starter.py \
    --output_dir cache/models \
    --init_ckpt /home/jue/v2/llama2-7b-shard \
    --data_path /home/jue/v1/fmengine-torch/data/llama-instruct/llama-instruct-19K.jsonl \
    --max_seq_len 4096 \
    --train_steps 1000 \
    --eval_steps 10 \
    --save_steps 100 \
    --log_steps 1 \
    --pipe_parallel_size 2 \
    --model_parallel_size 1 \
    --use_flash_attn true \
    --use_custom_llama true \
    --deepspeed_config ./configs/llama.json