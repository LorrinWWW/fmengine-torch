deepspeed --num_gpus 1 --num_nodes 1 cli/train.py \
    --output_dir .cache/models \
    --init_ckpt .cache/ckpts/llama-2-1b \
    --data_path .cache/data/prompt.jsonl \
    --max_seq_len 128 \
    --train_steps 1000 \
    --eval_steps 10 \
    --save_steps 100 \
    --log_steps 1 \
    --pipe_parallel_size 1 \
    --model_parallel_size 1 \
    --use_flash_attn false \
    --deepspeed_config ./configs/llama.json